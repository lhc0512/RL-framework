# environment
env_name: 'CartPole-v1'
##env_name: 'LunarLander-v2'
#max_episode_steps: 400
#state_dim: None
#action_dim: None


name: 'DuelingDoubleDQN'
lr: 0.001  # learning rate
gamma: 0.99  # discount factor
tau: 0.005  # soft target network update
hidden_dim: 64  # hidden layer dimension

# experience replay
buffer_size: 100000
batch_size: 512



# epsilon
epsilon: 1.0
epsilon_decay: 0.001
epsilon_mini: 0.01

# log
seed: 123

total_steps: 100000
save_steps: 100000
test_steps: 2000
test_num: 4

checkpoint_path: './model'